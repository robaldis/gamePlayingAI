{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a pre-trained model\n",
    "\n",
    "This notebook loads a pre-trained model and uses it to play games. \n",
    "Note that it does not render the image of the game, it just prints out the episodic score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.3 (SDL 2.0.16, Python 3.7.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# sanity check: can we create breakwall?\n",
    "import gym\n",
    "e = gym.make('gym_gs:BreakwallNoFrameskip-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install baselines and other stuff\n",
    "!pip install git+https://github.com/openai/baselines.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## full check - can we use the full opencv/ openai version \n",
    "## of the gym?\n",
    "\n",
    "# Script to test a pre-trained model\n",
    "# Written by Matthew Yee-King\n",
    "# MIT license \n",
    "# https://mit-license.org/\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "import random\n",
    "import time \n",
    "\n",
    "env_name = \"gym_gs:BreakwallNoFrameskip-v1\" \n",
    "# for notebook users - make sure you have uploaded your pre-trained\n",
    "# models... then adjust this to reflect the file path\n",
    "model_file = \"./pre-trained/mac_hard_breakwall/gym_gs:BreakwallNoFrameskip-v1_20211018-114642_5424\"\n",
    "\n",
    "def create_q_model(num_actions):\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(84, 84, 4,))\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)    \n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)    \n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)    \n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "def create_env(env_name, seed=42):\n",
    "    try:\n",
    "        # Use the Baseline Atari environment because of Deepmind helper functions\n",
    "        env = make_atari(env_name)\n",
    "        # Warp the frames, grey scale, stake four frame and scale to smaller ratio\n",
    "        env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "        print(\"Loaded gym\")\n",
    "        env.seed(seed)\n",
    "        return env\n",
    "    except:\n",
    "        print(\"Failed to make gym env\", env_name)\n",
    "        return None\n",
    "\n",
    "def run_sim(env, model, frame_count):\n",
    "    state = np.array(env.reset())\n",
    "    total_reward = 0\n",
    "    for i in range(frame_count):\n",
    "        # in the notebook version we cannot really \n",
    "        # render in realtime, so you just have\n",
    "        # to check the score :( \n",
    "        #env.render('human')\n",
    "        state_tensor = keras.backend.constant(state)\n",
    "        state_tensor = keras.backend.expand_dims(state_tensor, 0)\n",
    "        action_values = model(state_tensor, training=False)\n",
    "        # Take best action\n",
    "        action = keras.backend.argmax(action_values[0]).numpy()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        state =  np.array(state)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(\"Game over at frame\", i, \"rew\", total_reward)\n",
    "            env.reset()\n",
    "            #break\n",
    "        #time.sleep(0.1)\n",
    "    print(\"Sim ended : rew is \", total_reward)\n",
    "\n",
    "def main(env_name, model_file,frame_count=1000,  seed=42):\n",
    "    env = create_env(env_name=env_name)\n",
    "    assert env is not None, \"Failed to make env \" + env_name\n",
    "    model = create_q_model(num_actions=env.action_space.n)\n",
    "    model_testfile = model_file + \".data-00000-of-00001\"\n",
    "    assert os.path.exists(model_testfile), \"Failed to load model: \" + model_testfile\n",
    "    print(\"Model weights look loadable\", model_testfile)\n",
    "    model.load_weights(model_file)\n",
    "    print(\"Model loaded weights - starting sim\")\n",
    "    run_sim(env, model, frame_count)\n",
    "        \n",
    "main(env_name, model_file, frame_count=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
